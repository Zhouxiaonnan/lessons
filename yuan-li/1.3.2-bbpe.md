# 1.3.2 BBPE

论文：[Neural Machine Translation with Byte-Level Subwords (arxiv.org)](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1909.03341.pdf)

前置知识：[字节对编码（Byte Pair Encoding, BPE）分词技术 | Tokenization - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/691907658)

### 什么是BBPE

BBPE中文翻译为“字节级别的字节对编码“，简单来说就是将文本数据表示为字节序列，并将这些字节序列通过字节对编码的方式分割成更小的子词，最终构建一个用于模型训练的词汇表。

<figure><img src="https://pic4.zhimg.com/80/v2-658f94b2428e24113bac0322afa93613_720w.webp" alt="" height="214" width="666"><figcaption></figcaption></figure>

### BBPE解决了BPE的什么问题

#### OOV

BPE：依然会遇到OOV的问题，特别是对于中文和日语这样的字符量庞大的语言，模型容易遇到训练数据中未出现过的字符。

BBPE：将句子构建为UTF-8编码字节序列而非字符序列，再进行BPE进行学习，利用256个字节集作为词汇表，这样就能够覆盖所有字符，所以不会出现OOV问题。

#### 词表庞杂

BPE：在分词器学习时，会产生比较多的罕见词汇占用词表的情况，但这种罕见词汇却不会高频率出现在文本中，导致了词表臃肿的缺点。

BBPE：BBPE通过在字节级别上操作，能够创建一个更紧凑的词汇表，减少了对大量不常见字符的需要。

#### 跨语言共享

BPE：BPE词表可以做到跨语言分享，也就是要使用所谓的“联合BPE”的方式进行分词器的学习，主要就是将不同语言的文本放在一起进行BPE操作，但这又会造成词表庞杂的问题，而且也无法覆盖所有语言，一般只会两种语言放在一起进行联合BPE的训练。

BBPE：因为所有语言的字符都可以转换成字节编码，BBPE的词表天然可以做到跨语言共享。

#### 模型迁移

BPE：BPE模型在迁移时，由于遇到不同的语言，则需要重新训练分词器，理由与无法做到跨语言共享的缺点类似。

BBPE：BBPE由于其通用的字节级表示，可以更容易地迁移到新的语言，而无需重新训练词汇表。

#### 鲁棒性

BPE：遇到噪声和非标准字符时（类似于罕见词汇），BPE难以进行处理。

BBPE：字节级别的此表包含所有噪声和非标准字符，其鲁棒性更强。

### BBPE问题

#### 计算成本

由于将字符转换成字节后，其要处理的长度会变大，因此造成计算成本增加的问题，论文中提出可以使用字节级别的n-gram方法来减少计算成本。

#### 缺少上下文语义

BBPE得到的tokens很可能是完整的或者被切分的字符的不同组合，即有可能是一个切分字符的一部分，也有可能是多个被切分了的字符的组合，那么就需要知道字符的边界来避免产生歧义的发生。

作者是根据他们自己以往的研究经验，提供了两种方式来获取上下文信息：

* 深度卷积层：使用深度卷积层来提取局部上下文信息。
* 双向门控循环单元（Bi-GRU）：使用Bi-GRU层来捕捉上下文信息。

#### 无效字节序列

每一个字符都可以转换成有效的utf-8编码，但是经过拆分组合的utf-8编码不一定能够转换成有效的字符，为了解决这个问题，论文中提出了一种动态规划算法来保证转换的字符有效。

### BBPE的例子

看一个论文中的例子吧，其中1K，2K等代表的是最终此表的大小，显然1K的时候，只对字节进行了很少的拼接，而当词表达到32K时，就进行了更长的拼接。

<figure><img src="https://pic3.zhimg.com/80/v2-54e4ce44aed0a71afcbb9ffaa9503c4a_720w.webp" alt="" height="805" width="1345"><figcaption></figcaption></figure>

### 实验和分析

#### 词频均匀性

相比于Char和BPE，词表词频分布更加均匀：

<figure><img src="https://pic1.zhimg.com/80/v2-f4af81cf482f419ad1cf43955ae23404_720w.webp" alt="" height="400" width="1383"><figcaption></figcaption></figure>

词表词频更加均匀意味着BBPE不用像BPE一样去处理较多的罕见词汇。

#### 词表共享性

BBPE的词表共享性更佳

<figure><img src="https://pic1.zhimg.com/80/v2-ed63d5c6dc0dbde2fd789c88cd902158_720w.webp" alt="" height="424" width="666"><figcaption></figcaption></figure>

词表共享性更好，说明BBPE可以更方便地进行不同语言之间的迁移

#### 引入上下文信息对翻译质量的影响

无论是什么样的分词方法，采用卷积或者Bi-GRU的方式引入上下文信息，都能极大地提高翻译质量。

<figure><img src="https://pic2.zhimg.com/80/v2-99bfcab7f84cca9ca47522d3c959a549_720w.webp" alt="" height="488" width="671"><figcaption></figcaption></figure>

#### 各种模型的分数对比

相比于Char来说，BBPE并没有更好的表现，实际上BBPE的主要贡献，是解决了OOV，词表共享，多语言训练，迁移训练的问题。

<figure><img src="https://pic2.zhimg.com/80/v2-5bf68d9c8971ca946d4827ecb166c1f5_720w.webp" alt="" height="528" width="1393"><figcaption></figcaption></figure>
